{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-02T03:27:59.454008Z",
     "iopub.status.busy": "2025-03-02T03:27:59.453571Z",
     "iopub.status.idle": "2025-03-02T03:27:59.475833Z",
     "shell.execute_reply": "2025-03-02T03:27:59.474938Z",
     "shell.execute_reply.started": "2025-03-02T03:27:59.453985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T13:19:59.164499Z",
     "iopub.status.busy": "2025-03-01T13:19:59.164099Z",
     "iopub.status.idle": "2025-03-01T13:20:13.490046Z",
     "shell.execute_reply": "2025-03-01T13:20:13.488601Z",
     "shell.execute_reply.started": "2025-03-01T13:19:59.164464Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets\n",
    "!pip install tokenizers\n",
    "!pip install torchmetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T13:22:04.940763Z",
     "iopub.status.busy": "2025-03-01T13:22:04.940061Z",
     "iopub.status.idle": "2025-03-01T13:22:05.659622Z",
     "shell.execute_reply": "2025-03-01T13:22:05.658509Z",
     "shell.execute_reply.started": "2025-03-01T13:22:04.940720Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'transformer-from-scratch'...\n",
      "remote: Enumerating objects: 58, done.\u001b[K\n",
      "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
      "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
      "remote: Total 58 (delta 28), reused 43 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (58/58), 25.94 KiB | 5.19 MiB/s, done.\n",
      "Resolving deltas: 100% (28/28), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/PranavInani/transformer-from-scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T03:27:59.476970Z",
     "iopub.status.busy": "2025-03-02T03:27:59.476651Z",
     "iopub.status.idle": "2025-03-02T03:27:59.492274Z",
     "shell.execute_reply": "2025-03-02T03:27:59.491430Z",
     "shell.execute_reply.started": "2025-03-02T03:27:59.476940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd /kaggle/working/transformer-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T03:27:59.493296Z",
     "iopub.status.busy": "2025-03-02T03:27:59.493054Z",
     "iopub.status.idle": "2025-03-02T03:28:15.052432Z",
     "shell.execute_reply": "2025-03-02T03:28:15.051703Z",
     "shell.execute_reply.started": "2025-03-02T03:27:59.493277Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T03:28:15.053414Z",
     "iopub.status.busy": "2025-03-02T03:28:15.053136Z",
     "iopub.status.idle": "2025-03-02T06:38:42.272047Z",
     "shell.execute_reply": "2025-03-02T06:38:42.271094Z",
     "shell.execute_reply.started": "2025-03-02T03:28:15.053393Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Device name: Tesla P100-PCIE-16GB\n",
      "Device memory: 15.887939453125 GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e028a7c6e5f147efb7b27cec6c58f912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc7d37f9820492381835d31b89065fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset_infos.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9a96cbc8974eef8fcaaf93ca4a9519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/190M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcfc25bd29234c2db734fa8ec09882c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/85.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9671295de87041279f4d13f35c8102cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3757a0f5febe4fb3b8ea4c17d6ad4a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1659083 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc5b586fd454b0bb32e6d41b45bb0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e29485d4bb41d6ba71a2f509f66a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source sentence: 3015\n",
      "Max length of target sentence: 2763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/transformer-from-scratch/train.py:270: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "/kaggle/working/transformer-from-scratch/train.py:280: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(model_filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading model cfilt/iitb-english-hindi_weights/tmodel_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 02: 100%|██████████| 25924/25924 [3:06:48<00:00,  2.31it/s, loss=3.500]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: The DSP of the Roop-nagar vigilance bureau, Balveer Singh said, if the general public were vigilant against corruption then a corruption free society could be built.\n",
      "    TARGET: रूपनगर विजिलेंस ब्यूरो के डीएसपी बलवीर सिंह ने यदि आमलोग भ्रष्टाचार के खिलाफ विजिलेंस का साथ दे तो भ्रष्टाचारमुक्त समाज का निर्माण किया जा सकता है।\n",
      " PREDICTED: रो प् - नगर चौक सी ब्यूरो के डी पी एस ने कहा , यदि आम जनता भ्रष्टाचार के खिलाफ सावधान है तो भ्रष्टाचार मुक्त समाज का निर्माण किया जा सकता है ।\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Through this state-wide signature campaign, 10 Lakh (1 million)signatures across the state will be collected and handed over to the Governor.\n",
      "    TARGET: इस राज्यव्यापी हस्ताक्षर अभियान के माध्यम से प्रदेश भर में 10 लाख हस्ताक्षर करवाकर राज्यपाल को सौंपे जाएंगे।\n",
      " PREDICTED: इस राज्य व्यापी हस्ताक्षर अभियान के माध्यम से , 10 लाख ( 1 मिलियन ) के हस्ताक्षर एकत्र किए जाएंगे और राज्यपाल को दिये जाएंगे ।\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `CharErrorRate` from `torchmetrics` was deprecated and will be removed in 2.0. Import `CharErrorRate` from `torchmetrics.text` instead.\n",
      "  _future_warning(\n",
      "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `WordErrorRate` from `torchmetrics` was deprecated and will be removed in 2.0. Import `WordErrorRate` from `torchmetrics.text` instead.\n",
      "  _future_warning(\n",
      "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `BLEUScore` from `torchmetrics` was deprecated and will be removed in 2.0. Import `BLEUScore` from `torchmetrics.text` instead.\n",
      "  _future_warning(\n"
     ]
    }
   ],
   "source": [
    "from config import get_config\n",
    "\n",
    "# Update configuration for Colab environment\n",
    "cfg = get_config()\n",
    "cfg['model_folder'] = 'weights'  # Save weights in the working directory\n",
    "cfg['batch_size'] = 64  # Increased batch size to 64\n",
    "cfg['num_epochs'] = 3  # Reduced number of epochs for testing\n",
    "cfg['preload'] = 'latest'  # Start training from scratch (or use 'latest' if you have previous weights)\n",
    "cfg['use_amp'] = False \n",
    "cfg['seq_len'] = 95\n",
    "# Enable mixed precision training for faster execution\n",
    "\n",
    "from train import train_model\n",
    "\n",
    "# Train the model with the updated configuration\n",
    "train_model(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T06:38:42.278054Z",
     "iopub.status.busy": "2025-03-02T06:38:42.277730Z",
     "iopub.status.idle": "2025-03-02T06:38:42.284338Z",
     "shell.execute_reply": "2025-03-02T06:38:42.283739Z",
     "shell.execute_reply.started": "2025-03-02T06:38:42.278023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from config import get_config, latest_weights_file_path\n",
    "from train import get_model, get_ds, run_validation\n",
    "from translate import translate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T06:38:42.285226Z",
     "iopub.status.busy": "2025-03-02T06:38:42.285036Z",
     "iopub.status.idle": "2025-03-02T06:41:59.596561Z",
     "shell.execute_reply": "2025-03-02T06:41:59.595691Z",
     "shell.execute_reply.started": "2025-03-02T06:38:42.285208Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Max length of source sentence: 3015\n",
      "Max length of target sentence: 2763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-f2218c07bbfe>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(model_filename)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "config = get_config()\n",
    "train_dataloader, val_dataloader, test_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
    "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    "\n",
    "# Load the pretrained weights\n",
    "model_filename = latest_weights_file_path(config)\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T06:41:59.597817Z",
     "iopub.status.busy": "2025-03-02T06:41:59.597499Z",
     "iopub.status.idle": "2025-03-02T06:42:02.430177Z",
     "shell.execute_reply": "2025-03-02T06:42:02.429362Z",
     "shell.execute_reply.started": "2025-03-02T06:41:59.597787Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Ask yourself whether those orders were followed in the states?\n",
      "    TARGET: अपने आप से पूछिए कि क्या उन आदेशों का राज्यों में पालन हुआ?\n",
      " PREDICTED: क्या राज्य में इन आदेशों का पालन किया गया है ?\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: The Corporate Services Deputy V.P. was in the city but could not meet the Union officers.\n",
      "    TARGET: डिप्टी वीपी कॉरपोरेट सर्विसेज शहर में मौजूद रहे लेकिन यूनियन पदाधिकारियों से बातचीत नहीं हो सकी।\n",
      " PREDICTED: कंपनी सेवा उप वी . पी . शहर में थी , लेकिन संघ के अधिकारियों से मिलने नहीं पा सका ।\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: On Thursday intensive checks of trucks were carried out.\n",
      "    TARGET: गुरुवार को ट्रकों की सघन जाच हो रही थी।\n",
      " PREDICTED: बृह स्पति वार के गहन परीक्षण ों को किया गया ।\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Customers who come from far afield buy things from this market, but people are buying fewer things as things are getting more expensive.\n",
      "    TARGET: दूर दराज से आने वाले ग्राहक इसी बजार से समान खरीदते हैं, लेकिन बर्तन मंहगे होने के कारण लोग कम खरीददारी कर रहे हैं।\n",
      " PREDICTED: ऐसे ग्राहक जो इस बाजार से दूर - दूर तक वस्तुओं को खरीद ते हैं , लेकिन लोग कम से कम चीजें खरीद रहे हैं , जैसे कि चीजें अधिक महंगा हो रही हैं ।\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: He said no irregularities will be tolerated in the implementation of schemes.\n",
      "    TARGET: कहा कि योजनाओं के क्रियान्वयन में किसी प्रकार की अनियमितता बर्दाश्त नहीं की जाएगी।\n",
      " PREDICTED: उन्होंने कहा कि योजनाओं के कार्यान्वयन में कोई अनियमित ता नहीं रहेगी ।\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: The young man had been shot in the waist and shoulder with two bullets.\n",
      "    TARGET: युवक की कमर व पीठ पर दो गोली मारी गई है।\n",
      " PREDICTED: युवा व्यक्ति को कमर में गोली मार दी गई थी और दो बल् बों के साथ कंधे से कंध ा मिला था ।\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: The Corporation is accepting 80 to 90% payment of the bill, as part-payment.\n",
      "    TARGET: यदि निगम पार्ट पेमेंट ले रहा है तो उपभोक्ताओं को बिल का 80 से 90 प्रतिशत हिस्सा भरना पड़ रहा है।\n",
      " PREDICTED: निगम को आंशिक भुगतान के रूप में 80 से 90 प्रतिशत बिल का भुगतान स्वीकार किया जाता है ।\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: The chief of the PSS organises meetings arbitrarily.\n",
      "    TARGET: प्रमुख पंसस की बैठक मनमाने ढंग से करते हैं।\n",
      " PREDICTED: पीएस एस के मुख्य सदस्य गण मन माने ढंग से बैठकों का आयोजन करते हैं ।\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: The Canadian government is questioning NRIs about the income from their properties and the amount they received as pension, etc. from the Punjab or India.\n",
      "    TARGET: कैनेडा सरकार एनआरआई से पंजाब या भारत में अपनी जमीन जायदाद से होने वाली आय और पेंशन आदि से मिलने वाली रकम का हिसाब-किताब पूछ रही है।\n",
      " PREDICTED: कनाडा की सरकार अनिवासी भारतीयों से उनकी संपत्तियों से आय और पंजाब या भारत से पेंशन आदि के रूप में प्राप्त राशि के बारे में प्रश्न कर रही है ।\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: He appealed to the students to take inspiration from the life of Lord Sri Rama.\n",
      "    TARGET: उन्होंने विद्यार्थियों का आह्वान किया कि वे मर्यादा पुरुषोतम भगवान श्रीराम के जीवन से प्रेरणा लें।\n",
      " PREDICTED: उन्होंने विद्यार्थियों से अपील की कि वे भगवान श्री राम के जीवन से प्रेरणा ग्रहण करें ।\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Komal was immediately taken to the Multi-speciality Government Hospital, Sector-16, where she was declared dead on arrival.\n",
      "    TARGET: कोमल को तत्काल गवर्नमेंट मल्टीस्पेशिएलिटी अस्पताल, सेक्टर-16 में ले जाया गया जहां डाक्टरों ने उसे मृत लाई गई घोषित कर दिया।\n",
      " PREDICTED: को मा यल को तुरंत बहु - विशेष सरकारी अस्पताल , क्षेत्र - 16 में ले जाया गया , जहां उसे आने पर मृत्यु घोषित कर दिया गया ।\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Only after a post-mortem will the police be able to find out the actual cause of death.\n",
      "    TARGET: पोस्टमार्टम रिपोर्ट के बाद मृत्यु के वास्तविक कारणों का पता चल सकेगा।\n",
      " PREDICTED: मृत्यु के बाद ही पुलिस वास्तविक कारण खो जा सकेगा ।\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: We are expecting the sales of diamonds to go up by 25 percent this year.\n",
      "    TARGET: हमें हीरे की बिक्री पिछले साल की तुलना में इस साल 25 फीसदी अधिक रहने की उम्मीद है।\n",
      " PREDICTED: हम इस वर्ष 25 प्रतिशत तक की दर से ईंट की बिक्री की उम्मीद कर रहे हैं ।\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: The decision made by the Federal Reserve to continue supporting the American Economy with its relief package has created enthusiasm among foreign investors, which in turn has helped the domestic share market to make history on Thursday.\n",
      "    TARGET: अमेरिकी अर्थव्यवस्था को सहारा देने के लिए राहत पैकेज जारी रखने के फेड रिजर्व के फैसले से उत्साहित विदेशी संस्थागत निवेशकों की भारी लिवाली के बीच घरेलू शेयर बाजार ने गुरुवार को ऊंचाई का नया इतिहास बनाया।\n",
      " PREDICTED: संघीय रिजर्व द्वारा किए गए निर्णय ने अमेरिकी अर्थव्यवस्था को अपने राहत पैकेज के साथ सहयोग देने के लिए विदेशी निवेशकों के बीच उत्साह पैदा किया है , जिसने भू वार को इतिहास बनाने में घरेलू शेयर बाजार की मदद की है ।\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: The NRI, along with Armed forces personnel, have been providing security for their land.\n",
      "    TARGET: एनआरआई के साथ ही सेना कर्मियों की जमीन को भी सुरक्षा प्रदान की गई है।\n",
      " PREDICTED: भारतीय आर आई , सशस्त्र सेनाओं के साथ , अपनी भूमि के लिए सुरक्षा प्रदान कर रहे हैं ।\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: print(msg), 0, None, num_examples=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T06:42:02.431158Z",
     "iopub.status.busy": "2025-03-02T06:42:02.430926Z",
     "iopub.status.idle": "2025-03-02T06:42:04.658435Z",
     "shell.execute_reply": "2025-03-02T06:42:04.657716Z",
     "shell.execute_reply.started": "2025-03-02T06:42:02.431137Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/transformer-from-scratch/translate.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(model_filename, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SOURCE: How is your mood now?\n",
      " PREDICTED: अब तुम्हारा मन कैसा है ?\n"
     ]
    }
   ],
   "source": [
    "t = translate(\"How is your mood now?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T06:42:04.659850Z",
     "iopub.status.busy": "2025-03-02T06:42:04.659605Z",
     "iopub.status.idle": "2025-03-02T06:52:47.587082Z",
     "shell.execute_reply": "2025-03-02T06:52:47.586305Z",
     "shell.execute_reply.started": "2025-03-02T06:42:04.659829Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading model from cfilt/iitb-english-hindi_weights/tmodel_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/transformer-from-scratch/test.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(model_filename, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 2507/2507 [09:50<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "Character Error Rate (CER): 0.5964\n",
      "Word Error Rate (WER): 0.9610\n",
      "BLEU Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:70: FutureWarning: Importing `char_error_rate` from `torchmetrics.functional` was deprecated and will be removed in 2.0. Import `char_error_rate` from `torchmetrics.text` instead.\n",
      "  _future_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Translation Example:\n",
      "Source: And I think about my father.\n",
      "Target: और मैं अपने पिता के बारे में सोचता हूँ।\n",
      "Predicted: और मैं अपने पिता के बारे में सोचता हूँ ।\n",
      "CER: 0.0256\n",
      "\n",
      "Worst Translation Example:\n",
      "Source: Frontier's new carry-on fee won't start until summer, though a date hasn't been set.\n",
      "Target: Frontier का नया कैरी - ऑन फीस, गर्मियों तक शुरू नहीं  होगा यद्यपि एक तिथि निर्धारित नहीं  किया गया है.\n",
      "Predicted: सीमा पार करने वाले के नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए - नए\n",
      "CER: 2.0980\n",
      "\n",
      "Analysis plot saved as 'length_vs_error.png'\n",
      "Detailed results saved to 'test_results.txt'\n"
     ]
    }
   ],
   "source": [
    "%run test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T18:22:10.893309Z",
     "iopub.status.busy": "2025-03-01T18:22:10.892952Z",
     "iopub.status.idle": "2025-03-01T18:22:10.900223Z",
     "shell.execute_reply": "2025-03-01T18:22:10.899439Z",
     "shell.execute_reply.started": "2025-03-01T18:22:10.893278Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 8,\n",
       " 'num_epochs': 20,\n",
       " 'lr': 0.0001,\n",
       " 'seq_len': 70,\n",
       " 'd_model': 512,\n",
       " 'datasource': 'cfilt/iitb-english-hindi',\n",
       " 'lang_src': 'en',\n",
       " 'lang_tgt': 'hi',\n",
       " 'model_folder': 'weights',\n",
       " 'model_basename': 'tmodel_',\n",
       " 'preload': 'latest',\n",
       " 'tokenizer_file': 'tokenizer_{0}_bpe.json',\n",
       " 'experiment_name': 'runs/tmodel',\n",
       " 'vocab_size': 16000,\n",
       " 'use_amp': True}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import get_config\n",
    "get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T18:23:06.008745Z",
     "iopub.status.busy": "2025-03-01T18:23:06.008417Z",
     "iopub.status.idle": "2025-03-01T18:23:06.012269Z",
     "shell.execute_reply": "2025-03-01T18:23:06.011472Z",
     "shell.execute_reply.started": "2025-03-01T18:23:06.008718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T18:23:00.673775Z",
     "iopub.status.busy": "2025-03-01T18:23:00.673479Z",
     "iopub.status.idle": "2025-03-01T18:23:00.679378Z",
     "shell.execute_reply": "2025-03-01T18:23:00.678695Z",
     "shell.execute_reply.started": "2025-03-01T18:23:00.673752Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 8,\n",
       " 'num_epochs': 20,\n",
       " 'lr': 0.0001,\n",
       " 'seq_len': 70,\n",
       " 'd_model': 512,\n",
       " 'datasource': 'cfilt/iitb-english-hindi',\n",
       " 'lang_src': 'en',\n",
       " 'lang_tgt': 'hi',\n",
       " 'model_folder': 'weights',\n",
       " 'model_basename': 'tmodel_',\n",
       " 'preload': 'latest',\n",
       " 'tokenizer_file': 'tokenizer_{0}_bpe.json',\n",
       " 'experiment_name': 'runs/tmodel',\n",
       " 'vocab_size': 16000,\n",
       " 'use_amp': True}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
